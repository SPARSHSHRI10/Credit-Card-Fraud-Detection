{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Card Fraud using DNN Undersampling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "resPIfqfDLrl"
      },
      "source": [
        "*Detecting Fraudulent Transactions using imbalance data did not give much insight about how our model actually performs so we try to balance the imbalance data using undersampling technique and then calculate the performance metrics.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxQ3zzFBwpqB"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzK27vHvx4fl"
      },
      "source": [
        "data = pd.read_csv('creditcard.csv')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "NA65-Brzx7HH",
        "outputId": "df6f5e65-f0c3-4adb-92c9-d0b425bfd8cc"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjOP6Z-J5uWI",
        "outputId": "65fe7700-98ca-42ac-de41-d16db826d245"
      },
      "source": [
        "data.info"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of             Time         V1         V2  ...       V28  Amount  Class\n",
              "0            0.0  -1.359807  -0.072781  ... -0.021053  149.62      0\n",
              "1            0.0   1.191857   0.266151  ...  0.014724    2.69      0\n",
              "2            1.0  -1.358354  -1.340163  ... -0.059752  378.66      0\n",
              "3            1.0  -0.966272  -0.185226  ...  0.061458  123.50      0\n",
              "4            2.0  -1.158233   0.877737  ...  0.215153   69.99      0\n",
              "...          ...        ...        ...  ...       ...     ...    ...\n",
              "284802  172786.0 -11.881118  10.071785  ...  0.823731    0.77      0\n",
              "284803  172787.0  -0.732789  -0.055080  ... -0.053527   24.79      0\n",
              "284804  172788.0   1.919565  -0.301254  ... -0.026561   67.88      0\n",
              "284805  172788.0  -0.240440   0.530483  ...  0.104533   10.00      0\n",
              "284806  172792.0  -0.533413  -0.189733  ...  0.013649  217.00      0\n",
              "\n",
              "[284807 rows x 31 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RROKXd92yWi"
      },
      "source": [
        "data['Class'] = data['Class'].fillna(0).astype(int)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjtGV_i4yYSt"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, f1_score, recall_score"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoqRZfeiyeQc"
      },
      "source": [
        "**Scale data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auyPBQS1yZ7d"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "data['NormalizedAmount'] = scaler.fit_transform(data['Amount'].values.reshape(-1, 1))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwhF_1jLzDdR"
      },
      "source": [
        "data = data.drop(['Amount', 'Time'], axis = 1)\n",
        "y = data['Class']\n",
        "X = data.drop(['Class'], axis = 1)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d7Z50thCziU"
      },
      "source": [
        "# **Undersampling**\n",
        "Undersampling technique works by removing observations of majority class and therefore balances number of observation of 2 classes better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2AkX2uJy8Kw",
        "outputId": "d8ad388a-f70d-4e16-b241-55b95fe0d008"
      },
      "source": [
        "fraud_ind = np.array(data[data.Class == 1].index)\n",
        "num_frauds = len(fraud_ind)\n",
        "print(num_frauds)\n",
        "normal_ind = np.array(data[data.Class == 0].index)\n",
        "num_normal = len(normal_ind)\n",
        "print(num_normal)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "492\n",
            "284315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhHxjUz99MTe"
      },
      "source": [
        "normal_ind = data[data.Class == 0].index\n",
        "random_normal_ind = np.random.choice(normal_ind, num_frauds, replace = False)\n",
        "random_normal_ind = np.array(random_normal_ind)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzh8PX2d9cdX"
      },
      "source": [
        "under_sample_ind = np.concatenate( [fraud_ind, random_normal_ind])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSwaHF-N9fgV",
        "outputId": "82f432bb-cf24-4489-a956-11b5f31e9fc2"
      },
      "source": [
        "print(len(under_sample_ind))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsrT3T35-C_J"
      },
      "source": [
        "under_sample_data = data.iloc[under_sample_ind, :]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-O2j-07-IAx"
      },
      "source": [
        "X_undersample = under_sample_data.iloc[:, under_sample_data.columns != 'Class']\n",
        "y_undersample = under_sample_data.iloc[:, under_sample_data.columns == 'Class']"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgZm2cxJFlWh"
      },
      "source": [
        "**Split into testing and training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5UGz0cg-S9m"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_undersample, y_undersample, test_size = 0.3)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrngjPih-VsB"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5zUh6UO-fX5"
      },
      "source": [
        "**Building deep neural network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYDXL81L-bn-"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd-KEZD0_BGk"
      },
      "source": [
        "**Model architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_EDDSHK-730"
      },
      "source": [
        "model = Sequential()\n",
        "#add input layer\n",
        "model.add(Dense(input_dim = 29, units = 16, activation = 'relu'))\n",
        "#add 2nd hidden layer\n",
        "model.add(Dense(units = 24, activation = 'relu'))\n",
        "#add dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "#add 3rd hidden layer\n",
        "model.add(Dense(units = 20, activation = 'relu'))\n",
        "#add 4th hidden layer\n",
        "model.add(Dense(units = 24, activation = 'relu'))\n",
        "#add ouptut layer\n",
        "model.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvsLvPuq_K0E",
        "outputId": "9117dc81-4a12-49b1-80d1-8ebf786ce92f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                480       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 24)                408       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 24)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                500       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 24)                504       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 1,917\n",
            "Trainable params: 1,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApnPuOrd_QOC",
        "outputId": "13c8d787-e5ce-45e5-f10c-917e17b7f3a2"
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size = 15, epochs = 5)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 0.2201 - accuracy: 0.9302\n",
            "Epoch 2/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9390\n",
            "Epoch 3/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.9419\n",
            "Epoch 4/5\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.9375\n",
            "Epoch 5/5\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9433\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2bfd9e7a50>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf52uKsM_qfr",
        "outputId": "fd0a0641-093d-4cbf-8c65-e5a8d4154efc"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9155\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2195683866739273, 0.9155405163764954]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsWzf9ZK_izk"
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmy-Nr9y_0Hy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbH2yL07AAMP"
      },
      "source": [
        "# Plotting Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HUdYv4EADly",
        "outputId": "4aea4c95-3f18-44e9-8f62-05dbf68816ab"
      },
      "source": [
        "conf_matrix = confusion_matrix(y_test, y_pred.round())\n",
        "print(conf_matrix)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[149   2]\n",
            " [ 23 122]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "aL6H6cw7BQ0p",
        "outputId": "52ceaabb-fa3d-4f29-d9e7-3153aff3d8cc"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 540x540 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP4qV38WG8zq"
      },
      "source": [
        "**Calculating other performance metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn33KesTAMGF",
        "outputId": "963d04a4-22a8-427b-ef33-62aec7188bda"
      },
      "source": [
        "print(precision_score(y_test, y_pred.round()))\n",
        "print(recall_score(y_test, y_pred.round()))\n",
        "print(f1_score(y_test, y_pred.round()))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9838709677419355\n",
            "0.8413793103448276\n",
            "0.9070631970260223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FUH09xyHhAW"
      },
      "source": [
        "*We can see that we achieved an accuracy of around 92%. Also, we get a recall of 84% and a precision of 98%, which is quite an improvement.\n",
        "So we can see undersampling technique drastically improves precision, a result of which the non-frauds classified as frauds (false positives) decrease.*"
      ]
    }
  ]
}